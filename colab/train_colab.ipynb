{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen3-1.7B GSM8K PPO Training (VERL)\n",
    "\n",
    "| Model | GSM8K Accuracy |\n",
    "|---|---|\n",
    "| Qwen3-1.7B base | ~69.2% |\n",
    "| Qwen3-1.7B + PPO | ~82.7% |\n",
    "\n",
    "**Before running this notebook**, set up the environment in the Colab terminal:\n",
    "```bash\n",
    "git clone https://github.com/verl-project/verl /content/verl && pip install -e /content/verl\n",
    "pip install flash-attn --no-build-isolation\n",
    "pip install trl datasets sympy regex pandas pyarrow huggingface-hub\n",
    "git clone https://github.com/jiayiderekchen/LLM_RL /content/LLM_RL\n",
    "```\n",
    "See `COLAB_GUIDE.md` for full setup details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "gpu = torch.cuda.get_device_properties(0)\n",
    "GPU_MEM_GB = gpu.total_memory / 1e9\n",
    "print(f\"GPU : {gpu.name}\")\n",
    "print(f\"VRAM: {GPU_MEM_GB:.1f} GB\")\n",
    "IS_A100_OR_H100 = GPU_MEM_GB >= 38\n",
    "print(f\"Config: {'large (A100/H100)' if IS_A100_OR_H100 else 'small (T4)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive\n",
    "Checkpoints and logs are saved directly to Drive so they survive session resets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "DRIVE_DIR  = '/content/drive/MyDrive/LLM_RL_runs'\n",
    "CKPT_DIR   = f'{DRIVE_DIR}/checkpoints'\n",
    "LOG_FILE   = f'{DRIVE_DIR}/train.log'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "print(f'Checkpoints → {CKPT_DIR}')\n",
    "print(f'Log         → {LOG_FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone / Update Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DIR = '/content/LLM_RL'\n",
    "REPO_URL = 'https://github.com/jiayiderekchen/LLM_RL.git'\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    !git -C {REPO_DIR} pull\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HuggingFace Login\n",
    "Add `HF_TOKEN` to Colab Secrets (key icon in left sidebar) for one-click login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    login(token=userdata.get('HF_TOKEN'), add_to_git_credential=False)\n",
    "    print('Logged in via Colab secret.')\n",
    "except Exception:\n",
    "    login()  # interactive fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare GSM8K Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(REPO_DIR)\n",
    "!python data/prepare_gsm8k.py --output_dir data/gsm8k\n",
    "!ls -lh data/gsm8k/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PPO Training\n",
    "\n",
    "Runs `scripts/train_ppo.sh` and streams output to both notebook and Drive log file.\n",
    "\n",
    "> **Tip:** Enable *Background execution* (Runtime → Change runtime type) so the cell keeps running if the browser tab goes to sleep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, os\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# GPU-aware batch sizes\n",
    "if IS_A100_OR_H100:\n",
    "    extra_overrides = [\n",
    "        'data.train_batch_size=128',\n",
    "        'actor_rollout_ref.actor.ppo_mini_batch_size=64',\n",
    "        'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=4',\n",
    "        'actor_rollout_ref.rollout.gpu_memory_utilization=0.5',\n",
    "        'critic.ppo_micro_batch_size_per_gpu=4',\n",
    "    ]\n",
    "else:  # T4\n",
    "    extra_overrides = [\n",
    "        'data.train_batch_size=32',\n",
    "        'data.max_prompt_length=384',\n",
    "        'data.max_response_length=512',\n",
    "        'actor_rollout_ref.actor.ppo_mini_batch_size=16',\n",
    "        'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=2',\n",
    "        'actor_rollout_ref.actor.fsdp_config.param_offload=true',\n",
    "        'actor_rollout_ref.rollout.gpu_memory_utilization=0.35',\n",
    "        'critic.ppo_micro_batch_size_per_gpu=2',\n",
    "        'trainer.total_epochs=10',\n",
    "        'trainer.test_freq=50',\n",
    "    ]\n",
    "\n",
    "cmd = [\n",
    "    'bash', 'scripts/train_ppo.sh',\n",
    "    f'trainer.default_local_dir={CKPT_DIR}',\n",
    "] + extra_overrides\n",
    "\n",
    "env = {**os.environ, 'N_GPUS': '1'}\n",
    "\n",
    "print('Command:', ' '.join(cmd))\n",
    "print(f'Checkpoints → {CKPT_DIR}')\n",
    "print(f'Log         → {LOG_FILE}\\n')\n",
    "\n",
    "with open(LOG_FILE, 'w') as logf:\n",
    "    proc = subprocess.Popen(cmd, env=env,\n",
    "                            stdout=subprocess.PIPE,\n",
    "                            stderr=subprocess.STDOUT,\n",
    "                            text=True, bufsize=1)\n",
    "    for line in proc.stdout:\n",
    "        print(line, end='')   # stream to notebook\n",
    "        logf.write(line)       # write to Drive\n",
    "        logf.flush()\n",
    "    proc.wait()\n",
    "\n",
    "print(f'\\nTraining finished. Exit code: {proc.returncode}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitor Log (run while training is in progress)\n",
    "Run this cell in parallel to watch key metrics from the Drive log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re\n",
    "from IPython.display import clear_output\n",
    "\n",
    "POLL_S = 30\n",
    "step_re   = re.compile(r'global_step[:\\s]+(\\d+)')\n",
    "reward_re = re.compile(r'reward[\\w/]*[:\\s]+([\\d\\.]+)', re.I)\n",
    "\n",
    "print(f'Monitoring {LOG_FILE} — Ctrl+C to stop (training keeps running).')\n",
    "while True:\n",
    "    try:\n",
    "        lines = open(LOG_FILE).readlines() if os.path.exists(LOG_FILE) else []\n",
    "    except Exception:\n",
    "        lines = []\n",
    "\n",
    "    recent  = lines[-300:]\n",
    "    steps   = [int(m.group(1)) for l in recent if (m := step_re.search(l))]\n",
    "    rewards = [float(m.group(1)) for l in recent if (m := reward_re.search(l))]\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(f'=== Training Monitor [{time.strftime(\"%H:%M:%S\")}] ===')\n",
    "    print(f'Log lines : {len(lines)}')\n",
    "    print(f'Step      : {steps[-1] if steps else \"–\"}')\n",
    "    print(f'Reward    : {rewards[-1]:.4f}' if rewards else 'Reward    : –')\n",
    "    if len(rewards) >= 5:\n",
    "        print(f'Avg(last5): {sum(rewards[-5:])/5:.4f}')\n",
    "    print('\\n--- Last 15 lines ---')\n",
    "    for l in lines[-15:]:\n",
    "        print(l.rstrip())\n",
    "    time.sleep(POLL_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Checkpoint from Google Drive\n",
    "\n",
    "Run after training (or mid-training to check a specific step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Auto-detect latest checkpoint in Drive\n",
    "ckpts = sorted(glob.glob(f'{CKPT_DIR}/*/global_step_*'))\n",
    "if ckpts:\n",
    "    for c in ckpts:\n",
    "        print(c)\n",
    "    EVAL_CKPT = ckpts[-1]\n",
    "else:\n",
    "    print('No checkpoints found in Drive yet.')\n",
    "    EVAL_CKPT = None\n",
    "\n",
    "print(f'\\nWill evaluate: {EVAL_CKPT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override EVAL_CKPT manually if needed:\n",
    "# EVAL_CKPT = f'{CKPT_DIR}/qwen3_gsm8k_ppo/global_step_500'\n",
    "\n",
    "if EVAL_CKPT:\n",
    "    os.chdir(REPO_DIR)\n",
    "    !python evaluation/eval_gsm8k.py \\\n",
    "        --model_path {EVAL_CKPT} \\\n",
    "        --split test \\\n",
    "        --max_new_tokens 512 \\\n",
    "        --batch_size 16\n",
    "else:\n",
    "    print('Set EVAL_CKPT to a valid checkpoint path.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Base vs PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate base model for comparison\n",
    "os.chdir(REPO_DIR)\n",
    "!python evaluation/eval_gsm8k.py \\\n",
    "    --model_path Qwen/Qwen3-1.7B \\\n",
    "    --split test \\\n",
    "    --max_new_tokens 512 \\\n",
    "    --batch_size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of all eval results\n",
    "import json, glob\n",
    "\n",
    "result_files = sorted(glob.glob(f'{REPO_DIR}/evaluation/results/*.json'))\n",
    "print(f'{'Model':<55} {'Accuracy':>9}  Correct/Total')\n",
    "print('-' * 80)\n",
    "for rf in result_files:\n",
    "    with open(rf) as f:\n",
    "        r = json.load(f)['report']\n",
    "    name = os.path.basename(r['model_path'])\n",
    "    print(f\"{name:<55} {r['accuracy']*100:>8.2f}%  {r['correct']}/{r['total']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
